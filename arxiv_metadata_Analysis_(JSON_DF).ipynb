{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKV4p61s_KsL"
      },
      "source": [
        "# **Arxiv metadata Analytics with PySpark DF: JSON case study**\n",
        "\n",
        "### Udemy Course: Best Hands-on Big Data Practices and Use Cases using PySpark\n",
        "\n",
        "### Author: Amin Karami (PhD, FHEA)\n",
        "#### email: amin.karami@ymail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6LNmQMY_KsP"
      },
      "outputs": [],
      "source": [
        "########## ONLY in Colab ##########\n",
        "!pip3 install pyspark\n",
        "########## ONLY in Colab ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIvN-E9n_KsR"
      },
      "outputs": [],
      "source": [
        "########## ONLY in Ubuntu Machine ##########\n",
        "# Load Spark engine\n",
        "!pip3 install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "########## ONLY in Ubuntu Machine ##########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3YlWY9fC_KsR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/03/19 20:08:32 WARN Utils: Your hostname, Adrian-Laptop.local resolves to a loopback address: 127.0.0.1; using 192.168.100.19 instead (on interface en0)\n",
            "23/03/19 20:08:32 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/03/19 20:08:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "23/03/19 20:08:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
            "23/03/19 20:08:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://192.168.100.19:4042\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f83de94a670>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import SparkSession\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Z3p3JFE_KsS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 0:======================================================>  (24 + 1) / 25]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- abstract: string (nullable = true)\n",
            " |-- authors: string (nullable = true)\n",
            " |-- authors_parsed: array (nullable = true)\n",
            " |    |-- element: array (containsNull = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- comments: string (nullable = true)\n",
            " |-- doi: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- journal-ref: string (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            " |-- report-no: string (nullable = true)\n",
            " |-- submitter: string (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- update_date: string (nullable = true)\n",
            " |-- versions: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- created: string (nullable = true)\n",
            " |    |    |-- version: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Read and Load Data to Spark\n",
        "\n",
        "df = spark.read.json('data.json')\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "viS8zgdO_KsT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[abstract: string, authors: string, authors_parsed: array<array<string>>, categories: string, comments: string, doi: string, id: string, journal-ref: string, license: string, report-no: string, submitter: string, title: string, update_date: string, versions: array<struct<created:string,version:string>>]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check the partitions\n",
        "df.rdd.getNumPartitions()\n",
        "df.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2ivGTrR_KsU"
      },
      "source": [
        "## Question 1: Create a new Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x9AS1Xz__KsU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StructType([StructField('authors', StringType(), True), StructField('categories', StringType(), True), StructField('license', StringType(), True), StructField('comments', StringType(), True), StructField('abstract', StringType(), True), StructField('versions', ArrayType(StringType(), True), True)])\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "#Define schema\n",
        "Schema = StructType([\n",
        "    StructField('authors', StringType(), True),\n",
        "    StructField('categories', StringType(), True),\n",
        "    StructField('license', StringType(), True),\n",
        "    StructField('comments', StringType(), True),\n",
        "    StructField('abstract', StringType(), True),\n",
        "    StructField('versions', ArrayType(StringType()), True),\n",
        "\n",
        "])\n",
        "\n",
        "print(Schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nqC42SY_KsV"
      },
      "source": [
        "## Question 2: Binding Data to a Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4n3RZ0te_KsW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- authors: string (nullable = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- license: string (nullable = true)\n",
            " |-- comments: string (nullable = true)\n",
            " |-- abstract: string (nullable = true)\n",
            " |-- versions: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|             authors|       categories|             license|            comments|            abstract|            versions|\n",
            "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|C. Bal\\'azs, E. L...|           hep-ph|                null|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
            "|Ileana Streinu an...|    math.CO cs.CG|http://arxiv.org/...|To appear in Grap...|  We describe a n...|[{\"version\":\"v1\",...|\n",
            "|         Hongjun Pan|   physics.gen-ph|                null| 23 pages, 3 figures|  The evolution o...|[{\"version\":\"v1\",...|\n",
            "|        David Callan|          math.CO|                null|            11 pages|  We show that a ...|[{\"version\":\"v1\",...|\n",
            "|Wael Abu-Shammala...|  math.CA math.FA|                null|                null|  In this paper w...|[{\"version\":\"v1\",...|\n",
            "|Y. H. Pong and C....|cond-mat.mes-hall|                null|6 pages, 4 figure...|  We study the tw...|[{\"version\":\"v1\",...|\n",
            "|Alejandro Corichi...|            gr-qc|                null|16 pages, no figu...|  A rather non-st...|[{\"version\":\"v1\",...|\n",
            "|     Damian C. Swift|cond-mat.mtrl-sci|http://arxiv.org/...|   Minor corrections|  A general formu...|[{\"version\":\"v1\",...|\n",
            "|Paul Harvey, Brun...|         astro-ph|                null|                null|  We discuss the ...|[{\"version\":\"v1\",...|\n",
            "|  Sergei Ovchinnikov|          math.CO|                null|36 pages, 17 figures|  Partial cubes a...|[{\"version\":\"v1\",...|\n",
            "|Clifton Cunningha...|  math.NT math.AG|http://arxiv.org/...|14 pages; title c...|  In this paper w...|[{\"version\":\"v1\",...|\n",
            "|         Dohoon Choi|          math.NT|                null|                null|  Recently, Bruin...|[{\"version\":\"v1\",...|\n",
            "|Dohoon Choi and Y...|          math.NT|                null|                null|  Serre obtained ...|[{\"version\":\"v1\",...|\n",
            "|        Koichi Fujii|  math.CA math.AT|                null|  18 pages, 1 figure|  In this article...|[{\"version\":\"v1\",...|\n",
            "|     Christian Stahn|           hep-th|                null|22 pages; signs a...|  The pure spinor...|[{\"version\":\"v1\",...|\n",
            "|Chao-Hsi Chang, T...|           hep-ph|                null|17 pages, 3 figur...|  In this work, w...|[{\"version\":\"v1\",...|\n",
            "|Nceba Mhlahlo, Da...|         astro-ph|                null|10 pages, 11 figu...|  Results from sp...|[{\"version\":\"v1\",...|\n",
            "|  Andreas Gustavsson|           hep-th|                null|20 pages, v2: an ...|  We give a presc...|[{\"version\":\"v1\",...|\n",
            "|         Norio Konno|  math.PR math.AG|                null|6 pages, Journal-...|  In this note we...|[{\"version\":\"v1\",...|\n",
            "|The BABAR Collabo...|           hep-ex|                null|21 pages, 13 post...|  The shape of th...|[{\"version\":\"v1\",...|\n",
            "+--------------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.json(\"data.json\", schema=Schema)\n",
        "\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrizNbnA_KsW"
      },
      "source": [
        "## Question 3: Missing values for \"comments\" and \"license\" attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BElSJl-T_KsX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|             authors|          categories|             license|            comments|            abstract|            versions|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|C. Bal\\'azs, E. L...|              hep-ph|             unknown|37 pages, 15 figu...|  A fully differe...|[{\"version\":\"v1\",...|\n",
            "|Ileana Streinu an...|       math.CO cs.CG|http://arxiv.org/...|To appear in Grap...|  We describe a n...|[{\"version\":\"v1\",...|\n",
            "|         Hongjun Pan|      physics.gen-ph|             unknown| 23 pages, 3 figures|  The evolution o...|[{\"version\":\"v1\",...|\n",
            "|        David Callan|             math.CO|             unknown|            11 pages|  We show that a ...|[{\"version\":\"v1\",...|\n",
            "|Y. H. Pong and C....|   cond-mat.mes-hall|             unknown|6 pages, 4 figure...|  We study the tw...|[{\"version\":\"v1\",...|\n",
            "|Alejandro Corichi...|               gr-qc|             unknown|16 pages, no figu...|  A rather non-st...|[{\"version\":\"v1\",...|\n",
            "|     Damian C. Swift|   cond-mat.mtrl-sci|http://arxiv.org/...|   Minor corrections|  A general formu...|[{\"version\":\"v1\",...|\n",
            "|  Sergei Ovchinnikov|             math.CO|             unknown|36 pages, 17 figures|  Partial cubes a...|[{\"version\":\"v1\",...|\n",
            "|Clifton Cunningha...|     math.NT math.AG|http://arxiv.org/...|14 pages; title c...|  In this paper w...|[{\"version\":\"v1\",...|\n",
            "|        Koichi Fujii|     math.CA math.AT|             unknown|  18 pages, 1 figure|  In this article...|[{\"version\":\"v1\",...|\n",
            "|     Christian Stahn|              hep-th|             unknown|22 pages; signs a...|  The pure spinor...|[{\"version\":\"v1\",...|\n",
            "|Chao-Hsi Chang, T...|              hep-ph|             unknown|17 pages, 3 figur...|  In this work, w...|[{\"version\":\"v1\",...|\n",
            "|Nceba Mhlahlo, Da...|            astro-ph|             unknown|10 pages, 11 figu...|  Results from sp...|[{\"version\":\"v1\",...|\n",
            "|  Andreas Gustavsson|              hep-th|             unknown|20 pages, v2: an ...|  We give a presc...|[{\"version\":\"v1\",...|\n",
            "|         Norio Konno|     math.PR math.AG|             unknown|6 pages, Journal-...|  In this note we...|[{\"version\":\"v1\",...|\n",
            "|The BABAR Collabo...|              hep-ex|             unknown|21 pages, 13 post...|  The shape of th...|[{\"version\":\"v1\",...|\n",
            "|Vanessa Casagrand...|nlin.PS physics.c...|             unknown|  5 pages, 4 figures|  Spatiotemporal ...|[{\"version\":\"v1\",...|\n",
            "|Simon J.A. Malham...|             math.NA|             unknown| 20 pages, 4 figures|  We present Lie ...|[{\"version\":\"v1\",...|\n",
            "|M. A. Loukitcheva...|            astro-ph|             unknown|4 pages, 2 figure...|  The very nature...|[{\"version\":\"v1\",...|\n",
            "|A.A. Serga, M. Ko...|             nlin.PS|             unknown|First appeared in...|  The formation o...|[{\"version\":\"v1\",...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#drop \n",
        "\n",
        "df= df.dropna(subset=[\"comments\"])\n",
        "\n",
        "#replace\n",
        "df = df.fillna(value=\"unknown\", subset=[\"license\"])\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df.createOrReplaceTempView(\"Archive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiAO1VYb_KsX"
      },
      "source": [
        "## Question 4: Get the author names who published a paper in a 'math' category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "le9Cfbnk_KsY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|             authors|\n",
            "+--------------------+\n",
            "|Ileana Streinu an...|\n",
            "|        David Callan|\n",
            "|  Sergei Ovchinnikov|\n",
            "|Clifton Cunningha...|\n",
            "|        Koichi Fujii|\n",
            "|         Norio Konno|\n",
            "|Simon J.A. Malham...|\n",
            "|Robert P. C. de M...|\n",
            "|  P\\'eter E. Frenkel|\n",
            "|          Mihai Popa|\n",
            "|   Debashish Goswami|\n",
            "|      Mikkel {\\O}bro|\n",
            "|Nabil L. Youssef,...|\n",
            "|         Boris Rubin|\n",
            "|         A. I. Molev|\n",
            "| Branko J. Malesevic|\n",
            "|   John W. Robertson|\n",
            "|     Yu.N. Kosovtsov|\n",
            "|        Osamu Fujino|\n",
            "|Stephen C. Power ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 4:======================================>                  (17 + 8) / 25]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "304590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "#register DF to be use in SparkSQL\n",
        "\n",
        "sql_query= \"\"\"\n",
        "    SELECT \n",
        "        authors\n",
        "    FROM\n",
        "        Archive\n",
        "    WHERE\n",
        "        categories LIKE 'math%'\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(sql_query).show()\n",
        "\n",
        "print(spark.sql(sql_query).count())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5thkuIv_KsY"
      },
      "source": [
        "## Question 5: Get linceses with 5 or more letters in the \"abstract\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7LLuIkk_KsZ"
      },
      "outputs": [],
      "source": [
        "sql_query = \"\"\" SELECT distinct(license) FROM Archive\n",
        "                WHERE abstract REGEXP '%\\(([A-Za-z][^_ /\\\\<>]{5,})\\)%'\n",
        "            \"\"\"\n",
        "spark.sql(sql_query).show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hjELziqH_KsZ"
      },
      "source": [
        "## Question 6: Extract the statistic of the number of pages for unknown licenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1DYmkI8_KsZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def get_page(line):\n",
        "    search = re.findall('\\d+ pages', line)\n",
        "    if search:\n",
        "        return int(search[0].split(\" \")[0])\n",
        "    else :\n",
        "        return 0\n",
        "    \n",
        "\n",
        "spark.udf.register(\"PageNumbres\", get_page)\n",
        "\n",
        "sql_query1 = \"\"\"\n",
        "\n",
        "    SELECT\n",
        "        AVG(PageNumbres(comments)) AS avg,\n",
        "        SUM(PageNumbres(comments)) AS sum,\n",
        "        STD(PageNumbres(comments)) AS std\n",
        "    FROM\n",
        "        Archive\n",
        "    WHERE\n",
        "        license = 'unknown'\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "spark.sql(sql_query1).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(authors=\"C. Bal\\\\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan\", categories='hep-ph', license='unknown', comments='37 pages, 15 figures; published version', abstract='  A fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders. All\\nnext-to-leading order perturbative contributions from quark-antiquark,\\ngluon-(anti)quark, and gluon-gluon subprocesses are included, as well as\\nall-orders resummation of initial-state gluon radiation valid at\\nnext-to-next-to-leading logarithmic accuracy. The region of phase space is\\nspecified in which the calculation is most reliable. Good agreement is\\ndemonstrated with data from the Fermilab Tevatron, and predictions are made for\\nmore detailed tests with CDF and DO data. Predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the Large Hadron\\nCollider (LHC). Distributions of the diphoton pairs from the decay of a Higgs\\nboson are contrasted with those produced from QCD processes at the LHC, showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events.\\n', versions=['{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"}', '{\"version\":\"v2\",\"created\":\"Tue, 24 Jul 2007 20:10:27 GMT\"}']),\n",
              " Row(authors='Ileana Streinu and Louis Theran', categories='math.CO cs.CG', license='http://arxiv.org/licenses/nonexclusive-distrib/1.0/', comments='To appear in Graphs and Combinatorics', abstract='  We describe a new algorithm, the $(k,\\\\ell)$-pebble game with colors, and use\\nit obtain a characterization of the family of $(k,\\\\ell)$-sparse graphs and\\nalgorithmic solutions to a family of problems concerning tree decompositions of\\ngraphs. Special instances of sparse graphs appear in rigidity theory and have\\nreceived increased attention in recent years. In particular, our colored\\npebbles generalize and strengthen the previous results of Lee and Streinu and\\ngive a new proof of the Tutte-Nash-Williams characterization of arboricity. We\\nalso present a new decomposition that certifies sparsity based on the\\n$(k,\\\\ell)$-pebble game with colors. Our work also exposes connections between\\npebble game algorithms and previous sparse graph algorithms by Gabow, Gabow and\\nWestermann and Hendrickson.\\n', versions=['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 02:26:18 GMT\"}', '{\"version\":\"v2\",\"created\":\"Sat, 13 Dec 2008 17:26:00 GMT\"}'])]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/0w/_k96360175sff4w3b2nb6ts40000gn/T/ipykernel_19273/1360164601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\": '\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mget_Day_from_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/var/folders/0w/_k96360175sff4w3b2nb6ts40000gn/T/ipykernel_19273/1360164601.py\u001b[0m in \u001b[0;36mget_Day_from_version\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_Day_from_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\": '\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\": '\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_Day_from_version(item) :\n",
        "    values = ''.join(str(v) for v in item)\n",
        "    \n",
        "    print(values.split(\",\")[1].split(\": '\")[1])\n",
        "    return values.split(\",\")[1].split(\": '\")[1]\n",
        "\n",
        "get_Day_from_version('{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_page(line):\n",
        "    search = re.findall('\\d+ pages', line)\n",
        "    if search:\n",
        "        return int(search[0].split(\" \")[0])\n",
        "    else :\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'iloc'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/0w/_k96360175sff4w3b2nb6ts40000gn/T/ipykernel_19273/447689610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1986\u001b[0m         \"\"\"\n\u001b[1;32m   1987\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1988\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1989\u001b[0m                 \u001b[0;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'iloc'"
          ]
        }
      ],
      "source": [
        "print(df.iloc[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = df.limit(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3=df2.rdd.map(lambda x: x['versions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['{\"version\":\"v1\",\"created\":\"Mon, 2 Apr 2007 19:18:42 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Tue, 24 Jul 2007 20:10:27 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 02:26:18 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Sat, 13 Dec 2008 17:26:00 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sun, 1 Apr 2007 20:46:54 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Sat, 8 Dec 2007 23:47:24 GMT\"}',\n",
              "  '{\"version\":\"v3\",\"created\":\"Sun, 13 Jan 2008 00:36:28 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 03:16:14 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 04:24:59 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 04:27:22 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Wed, 22 Aug 2007 22:42:11 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 04:47:20 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Thu, 10 Apr 2008 08:42:28 GMT\"}',\n",
              "  '{\"version\":\"v3\",\"created\":\"Tue, 1 Jul 2008 18:54:28 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 05:10:16 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sat, 31 Mar 2007 05:32:49 GMT\"}',\n",
              "  '{\"version\":\"v2\",\"created\":\"Tue, 19 Aug 2008 04:46:47 GMT\"}',\n",
              "  '{\"version\":\"v3\",\"created\":\"Wed, 20 Aug 2008 13:15:09 GMT\"}'],\n",
              " ['{\"version\":\"v1\",\"created\":\"Sun, 1 Apr 2007 12:04:13 GMT\"}']]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.take(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.rdd.map(lambda x: (get_Day_from_version(x['versions']), (get_page(x['comments'] if x['comments'] != None else \"None\"), 1)))\\\n",
        ".take(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "arxiv-metadata_Analysis (JSON_DF).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
